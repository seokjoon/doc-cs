# CHAPTER 1 소개
## 1.3 scikit-learn
* 1.3.1 scikit-learn 설치
    * pip install numpy scipy matplotlib ipython scikit-learn pandas pillow
## 1.4 필수 라이브러리와 도구들
* 1.4.1 주피터 노트북
    * pip install jupyterlab
    * jupyter-lab --allow-root --ip='*' --NotebookApp.token='' --NotebookApp.password=''
* 1.4.2 NumPy
* 1.4.3 SciPy
* 1.4.4 matplotlib
* 1.4.5 pandas
* 1.4.6 mglearn
## 1.6 이 책에서 사용하는 소프트웨어 버전
## 1.7 첫 번째 애플리케이션: 붓꽃의 품종 분류
* 1.7.1 데이터 적재
* 1.7.2 성과 측정: 훈련 데이터와 테스트 데이터
* 1.7.3 가장 먼저 할 일: 데이터 살펴보기
* 1.7.4 첫 번째 머신러닝 모델: k-최근접 이웃 알고리즘
* 1.7.5 예측하기
* 1.7.6 모델 평가하기


# CHAPTER 2 지도 학습
## 2.1 분류와 회귀
## 2.2 일반화, 과대적합, 과소적합
* 2.2.1 모델 복잡도와 데이터셋 크기의 관계
## 2.3 지도 학습 알고리즘
* 2.3.1 예제에 사용할 데이터셋
* 2.3.2 k-최근접 이웃
* 2.3.3 선형 모델
* 2.3.4 나이브 베이즈 분류기
* 2.3.5 결정 트리
* 2.3.6 결정 트리의 앙상블
* 2.3.7 (한국어판 부록) 배깅, 엑스트라 트리, 에이다부스트
* 2.3.8 커널 서포트 벡터 머신
* 2.3.9 신경망(딥러닝)
## 2.4 분류 예측의 불확실성 추정
* 2.4.1 결정 함수
* 2.4.2 예측 확률
* 2.4.3 다중 분류에서의 불확실성


# CHAPTER 3 비지도 학습과 데이터 전처리
## 3.1 비지도 학습의 종류
## 3.2 비지도 학습의 도전 과제
## 3.3 데이터 전처리와 스케일 조정
* 3.3.1 여러 가지 전처리 방법
* 3.3.2 데이터 변환 적용하기
* 3.3.3 (한국어판 부록) QuantileTransformer와 PowerTransformer
* 3.3.4 훈련 데이터와 테스트 데이터의 스케일을 같은 방법으로 조정하기
* 3.3.5 지도 학습에서 데이터 전처리 효과
## 3.4 차원 축소, 특성 추출, 매니폴드 학습
* 3.4.1 주성분 분석(PCA)
* 3.4.2 비음수 행렬 분해(NMF)
* 3.4.3 t-SNE를 이용한 매니폴드 학습
## 3.5 군집
* 3.5.1 k-평균 군집
* 3.5.2 병합 군집
* 3.5.3 DBSCAN
* 3.5.4 군집 알고리즘의 비교와 평가
* 3.5.5 군집 알고리즘 요약


# CHAPTER 4 데이터 표현과 특성 공학
## 4.1 범주형 변수
* 4.1.1 원-핫-인코딩(가변수)
* 4.1.2 숫자로 표현된 범주형 특성
## 4.2 OneHotEncoder와 ColumnTransformer: scikit-learn으로 범주형 변수 다루기
## 4.3 make_column_transformer로 간편하게 ColumnTransformer 만들기
## 4.4 구간 분할, 이산화 그리고 선형 모델, 트리 모델
## 4.5 상호작용과 다항식
## 4.6 일변량 비선형 변환
## 4.7 특성 자동 선택
* 4.7.1 일변량 통계
* 4.7.2 모델 기반 특성 선택
* 4.7.3 반복적 특성 선택
## 4.8 전문가 지식 활용


# CHAPTER 5 모델 평가와 성능 향상
## 5.1 교차 검증
* 5.1.1 scikit-learn의 교차 검증
* 5.1.2 교차 검증의 장점
* 5.1.3 계층별 k-겹 교차 검증과 그외 전략들
* 5.1.4 (한국어판 부록) 반복 교차 검증
## 5.2 그리드 서치
* 5.2.1 간단한 그리드 서치
* 5.2.2 매개변수 과대적합과 검증 세트
* 5.2.3 교차 검증을 사용한 그리드 서치
## 5.3 평가 지표와 측정
* 5.3.1 최종 목표를 기억하라
* 5.3.2 이진 분류의 평가 지표
* 5.3.3 다중 분류의 평가 지표
* 5.3.4 회귀의 평가 지표
* 5.3.5 모델 선택에서 평가 지표 사용하기


# CHAPTER 6 알고리즘 체인과 파이프라인
## 6.1 데이터 전처리와 매개변수 선택
## 6.2 파이프라인 구축하기
## 6.3 그리드 서치에 파이프라인 적용하기
## 6.4 파이프라인 인터페이스
* 6.4.1 make_pipleline을 사용한 파이프라인 생성
* 6.4.2 단계 속성에 접근하기
* 6.4.3 그리드 서치 안의 파이프라인 속성에 접근하기
## 6.5 전처리와 모델의 매개변수를 위한 그리드 서치
## 6.6 모델 선택을 위한 그리드 서치
* 6.6.1 중복 계산 피하기


# CHAPTER 7 텍스트 데이터 다루기
## 7.1 문자열 데이터 타입
## 7.2 예제 애플리케이션: 영화 리뷰 감성 분석
## 7.3 텍스트 데이터를 BOW로 표현하기
* 7.3.1 샘플 데이터에 BOW 적용하기
* 7.3.2 영화 리뷰에 대한 BOW
## 7.4 불용어
## 7.5 tf?idf로 데이터 스케일 변경하기
## 7.6 모델 계수 조사
## 7.7 여러 단어로 만든 BOW(n-그램)
## 7.8 고급 토큰화, 어간 추출, 표제어 추출
* 7.8.1 (한국어판 부록) KoNLPy를 사용한 영화 리뷰 분석
## 7.9 토픽 모델링과 문서 군집화
* 7.9.1 LDA


# CHAPTER 8 마무리
## 8.1 머신러닝 문제 접근 방법
* 8.1.1 의사 결정 참여
## 8.2 프로토타입에서 제품까지
## 8.3 제품 시스템 테스트
## 8.4 나만의 추정기 만들기
## 8.5 더 배울 것들
* 8.5.1 이론
* 8.5.2 다른 머신러닝 프레임워크와 패키지
* 8.5.3 랭킹, 추천 시스템과 그 외 다른 알고리즘
* 8.5.4 확률 모델링, 추론, 확률적 프로그래밍
* 8.5.5 신경망
* 8.5.6 대규모 데이터셋으로 확장
* 8.5.7 실력 기르기