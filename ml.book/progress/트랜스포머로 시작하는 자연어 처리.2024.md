		1장 트랜스포머란 무엇인가?
    1.1 트랜스포머 생태계
    1.2 트랜스포머로 NLP 모델 최적화
    1.3 어떤 리소스를 사용해야 하나요?
    1.4 정리하기
    1.5 문제
    1.6 참고 문헌

    2장 트랜스포머 모델 아키텍처 살펴보기
    2.1 트랜스포머의 시작: Attention is All You Need
    2.2 학습과 성능
    2.3 허깅페이스의 트랜스포머 모델
    2.4 정리하기
    2.5 문제
    2.6 참고 문헌

    3장 BERT 모델 미세 조정하기
    3.1 BERT 아키텍처
    3.2 BERT 미세 조정하기
    3.3 정리하기
    3.4 문제
    3.5 참고 문헌

    4장 RoBERTa 모델 처음부터 사전 학습하기
    4.1 토크나이저 학습하기 및 트랜스포머 사전 학습하기
    4.2 처음부터 KantaiBERT 구축하기
    4.3 다음 단계
    4.4 정리하기
    4.5 문제
    4.6 참고 문헌

    5장 RoBERTa 모델 처음부터 사전 학습하기
    5.1 트랜스포머의 트랜스덕션과 귀납적 상속
    5.2 트랜스포머 성능 vs 인간 기준값
    5.3 다운스트림 작업 실행하기
    5.4 정리하기
    5.5 문제
    5.6 참고 문헌

    6장 트랜스포머를 사용한 기계 번역
    6.1 기계 번역 정의하기
    6.2 WMT 데이터셋 전처리하기
    6.3 BLEU로 기계 번역 평가하기
    6.4 구글 번역으로 번역하기
    6.5 트랙스로 번역하기
    6.6 정리하기
    6.7 문제
    6.8 참고 문헌

    7장 GPT-3 엔진을 사용한 초인간 트랜스포머 등장
    7.1 GPT-3 트랜스포머 모델을 사용한 초인간 NLP
    7.2 OpenAI GPT 트랜스포머 모델의 아키텍처
    7.3 GPT-2를 사용한 일반 텍스트 완성
    7.4 커스텀 GPT-2 언어 모델 학습
    7.5 OpenAI GPT-3 작업 실행하기
    7.6 GPT-2와 GPT-3의 출력 비교하기
    7.7 GPT-3 미세 조정하기
    7.8 4차 산업혁명 AI 전문가의 역할
    7.9 정리하기
    7.10 문제
    7.11 참고 문헌

    8장 법률 및 금융 문서에 트랜스포머를 적용하여 요약하기
    8.1 범용 텍스트 투 텍스트 모델 디자인하기
    8.2 T5를 사용해 요약하기
    8.3 GPT-3로 요약하기
    8.4 정리하기
    8.5 문제
    8.6 참고 문헌

    9장 데이터셋에 적합한 토크나이저
    9.1 데이터셋에 적합한 토크나이저
    9.2 특정 어휘가 포함된 표준 NLP 작업
    9.3 GPT-3의 범위 살펴보기
    9.4 정리하기
    9.5 문제
    9.6 참고 문헌

    10장 BERT 기반 트랜스포머를 사용한 SRL
    10.1 SRL(Semantic Role Labeling, 의미역 결정)
    10.2 BERT 기반 모델을 사용한 SRL 실험
    10.3 기본 예시
    10.4 어려운 예시
    10.5 SRL 적용 범위에 대한 의문
    10.6 정리하기
    10.7 문제
    10.8 참고 문헌

    11장 데이터가 말하게 하기: 스토리, 질문, 답변
    11.1 방법론
    11.2 방법 0: 시행착오
    11.3 방법 1: NER
    11.4 방법 2: SRL
    11.5 다음 단계
    11.6 정리하기
    11.7 문제
    11.8 참고 문헌

    12장 고객 감정을 감지해 예측하기
    12.1 SST(Stanford Sentiment Treebank)
    12.2 감성 분석으로 고객 행동 예측하기
    12.3 GPT-3를 사용한 감성 분석
    12.4 4차 산업 시대에 관한 몇 가지 생각
    12.5 정리하기
    12.6 문제
    12.7 참고 문헌

    13장 트랜스포머로 가짜 뉴스 분석하기
    13.1 가짜 뉴스에 대한 감정 반응
    13.2 가짜 뉴스에 대한 이성적 접근법
    13.3 마치기 전에
    13.4 정리하기
    13.5 문제
    13.6 참고 문헌

    14장 블랙박스 트랜스포머 모델 해석하기
    14.1 BertViz로 트랜스포머 시각화하기
    14.2 LIT
    14.3 딕셔너리 러닝을 활용한 트랜스포머 시각화
    14.4 내부를 볼 수 없는 모델 분석하기
    14.5 정리하기
    14.6 문제
    14.7 참고 문헌

    15장 NLP부터 범용 트랜스포머 모델까지
    15.1 모델과 생태계 선택하기
    15.2 리포머
    15.3 DeBERTa
    15.4 범용 모델에서 비전 트랜스포머까지
    15.5 확장되는 모델 세계
    15.6 정리하기
    15.7 문제
    15.8 참고 문헌

    16장 트랜스포머 기반 코파일럿의 등장
    16.1 프롬프트 엔지니어링
    16.2 코파일럿
    16.3 도메인별 GPT-3 엔진
    16.4 컴퓨터 비전
    16.5 메타버스에서 인간과 AI 코파일럿
    16.6 정리하기
    16.7 문제
    16.8 참고 문헌

    17장 초인간 트랜스포머를 사용한 OpenAI의 ChatGPT와 GPT-4
    17.1 ChatGPT와 GPT-4에 초인간 NLP 연동하기
    17.2 ChatGPT API 시작하기
    17.3 ChatGPT Plus로 코드와 주석 작성하기
    17.4 GPT-4 API 시작하기
    17.5 고급 프롬프트 엔지니어링
    17.6 설명 가능한 AI(XAI)
    17.7 DALL-E 2 API 시작하기
    17.8 모든 것을 종합하기
    17.9 정리하기
    17.10 문제
    17.11 참고 문헌

    부록 Ⅰ 트랜스포머 용어 설명
    Ⅰ.1 스택
    Ⅰ.2 서브 층
    Ⅰ.3 어텐션 헤드

    부록 Ⅱ 트랜스포머 모델의 하드웨어 제약사항
    Ⅱ.1 트랜스포머의 아키텍처와 규모
    Ⅱ.2 GPU가 특별한 이유
    Ⅱ.3 GPU는 병렬 연산을 위해 설계되었다
    Ⅱ.4 GPU는 또한 행렬 곱셈을 위해 설계되었다
    Ⅱ.5 GPU를 사용하는 코드
    Ⅱ.6 구글 코랩으로 GPU 테스트하기
    Ⅱ.7 구글 코랩의 무료 CPU
    Ⅱ.8 구글 코랩의 유료 CPU

    부록 Ⅲ GPT-2를 사용한 일반 텍스트 완성
    Ⅲ.1 1단계: GPU 활성화
    Ⅲ.2 2단계: OpenAI GPT-2 저장소 복제하기
    Ⅲ.3 3단계: 요구사항 설치하기
    Ⅲ.4 4단계: 텐서플로우 버전 확인하기
    Ⅲ.5 5단계: 345M 파라미터 GPT-2 모델 다운로드하기
    Ⅲ.6 6~7단계: 중간 지침
    Ⅲ.7 7b~8단계: 모델 가져오기 및 정의하기
    Ⅲ.8 9단계: GPT-2와 상호 작용하기
    Ⅲ.9 참고 문헌

    부록 Ⅳ GPT-2를 사용해 커스텀 텍스트 완성하기
    Ⅳ.1 GPT-2 모델 학습하기
    Ⅳ.2 참고 문헌

