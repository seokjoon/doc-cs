# [3부] 딥러닝을 이용한 텍스트 분석

## 13장: 딥러닝 소개
* 13.1 신경망
 * 13.1.1 신경망 소개
 * 13.1.2 신경망의 작동 원리
* 13.2 활성화 함수
 * 13.2.1 시그모이드 함수
 * 13.2.2 하이퍼볼릭 탄젠트 함수
 * 13.2.3 ReLU 함수
 * 13.2.4 Leaky ReLU 함수
 * 13.2.5 ELU 함수
 * 13.2.6 소프트플러스 함수
 * 13.2.7 GELU 함수
* 13.3 경사하강법
 * 13.3.1 사용되는 관측치의 수에 따른 경사하강법 구분
 * 13.3.2 신경망에서의 경사하강법 작동 원리
 * 13.3.3 오차 역전파
 * 13.3.4 경사 소실 문제
 * 13.3.5 경사 폭발 문제
 * 13.3.6 옵티마이저의 종류
 * 13.3.7 가중치 감쇠와 학습률 감쇠
* 13.4 가중치 초기화
 * 13.4.1 Xavier 초기화 방법
 * 13.4.2 He 초기화 방법
* 13.5 예제: 도시의 평균 집값 예측하기
 * 13.5.1 SGD 옵티마이저의 사용 예
 * 13.5.2 RMSprop 옵티마이저 사용의 예
 * 13.5.3 Adam 옵티마이저의 사용 예
* 13.6 신경망에서의 과적합 해결 방법
 * 13.6.1 L1/L2 규제화
 * 13.6.2 드롭아웃
 * 13.6.3 조기 종료
 * 13.6.4 배치 정규화
 * 13.6.5 계층 정규화


## 14장: FNN을 이용한 텍스트 분석과 단어 및 문서 임베딩
* 14.1 FNN을 이용한 텍스트 분석
* 14.2 단어 임베딩
 * 14.2.1 원-핫 벡터와 단어 임베딩
 * 14.2.2 Word2vec
 * 14.2.3 FastText
* 14.3 문서 임베딩
 * 14.3.1 Doc2vec


## 15장: CNN을 이용한 텍스트 분석
* 15.1 CNN
 * 15.1.1 CNN 소개
 * 15.1.2 파이썬 코딩하기
* 15.2 CNN을 이용한 텍스트 분석
 * 15.2.1 CNN에서의 문서 표현
 * 15.2.2 파이썬 코딩하기


## 16장: 순환신경망 기반 알고리즘을 이용한 텍스트 분석
* 16.1 RNN
 * 16.1.1 RNN 소개
 * 16.1.2 RNN을 이용한 감성분석
 * 16.1.3 각 단어의 은닉 상태 벡터를 모두 사용하기
 * 16.1.4 여러 개의 RNN 층 사용하기
* 16.2 LSTM
 * 16.2.1 LSTM 소개
 * 16.2.2 LSTM을 이용한 감성분석
 * 16.2.3 양방향 LSTM
 * 16.2.4 양방향 LSTM을 사용한 감성분석
* 16.3 seq2seq


## 17장: 트랜스포머
* 17.1 어텐션 알고리즘
* 17.2 셀프 어텐션
* 17.3 트랜스포머에서의 어텐션
* 17.4 트랜스포머 소개
 * 17.4.1 트랜스포머의 구조
 * 17.4.2 인코더 부분
 * 17.4.3 디코더 부분
 * 17.4.4 트랜스포머의 인코더 블록을 이용한 감성분석


## 18장: BERT
* 18.1 BERT의 구조
 * 18.1.1 BERT 내부 구조
 * 18.1.2 BERT 학습
 * 18.1.3 BERT 논문에서 사용된 다운스트림 작업
 * 18.1.4 BERT를 이용한 각 단어의 벡터 추출하기
* 18.2 파이썬 코딩하기
 * 18.2.1 BERT를 사용한 단어와 문장/문서의 벡터 추출하기
 * 18.2.2 영어 텍스트 감성분석
 * 18.2.3 한글 텍스트 감성분석


## 19장: BERT 기반 방법들
* 19.1 ALBERT
 * 19.1.1 ALBERT 소개
 * 19.1.2 파이썬 코딩하기
* 19.2 RoBERTa
 * 19.2.1 RoBERTa 소개
 * 19.2.2 파이썬 코딩하기
* 19.3 ELECTRA
 * 19.3.1 ELECTRA 소개
 * 19.3.2 파이썬 코딩하기
* 19.4 지식 증류 기반 방법들
 * 19.4.1 지식 증류
 * 19.4.2 DistilBERT
 * 19.4.3 TinyBERT
* 19.5 BERTopic
 * 19.5.1 문서 임베딩
 * 19.5.2 문서 군집화
 * 19.5.3 각 군집(토픽)을 나타내는 단어 찾기
 * 19.5.4 파이썬 코딩하기


## 20장: GPT 모형들
* 20.1 GPT-1
 * 20.1.1 GPT-1에서의 학습
* 20.2 GPT-2
 * 20.2.1 학습 데이터
 * 20.2.2 모형의 구조
 * 20.2.3 모형의 성능
 * 20.2.4 파이썬 코딩하기
* 20.3 GPT-3
 * 20.3.1 제로샷, 원샷, 퓨샷
 * 20.3.2 학습 데이터
 * 20.3.3 모형의 구조
 * 20.3.4 모형의 성능
 * 20.3.5 GPT-3 미세조정하기
* 20.4 InstructGPT
 * 20.4.1 InstructGPT에서의 미세 조정
 * 20.4.2 모형의 성능
* 20.5 ChatGPT


## 21장: 비전 트랜스포머를 이용한 텍스트 분석
* 21.1 ViT 소개
* 21.2 ViT를 이용한 이미지 분류
* 21.3 ViT를 이용한 텍스트 분류
 * 21.3.1 방법 1: N×D 문서에서 직접 패치를 추출
 * 21.3.2 방법 2: 문서를 패치로 분할하기 전에 Conv1D 필터 적용하기
 * 21.3.3 방법 3: N×C 결과물에서 C×C 패치 추출하기


## 22장: 오토인코더를 이용한 텍스트 분석
* 22.1 오토인코더 소개
* 22.2 오토인코더를 MNIST 데이터에 적용해 보기
* 22.3 오토인코더를 이용해 문서를 저차원 벡터로 표현하기
 * 22.3.1 LSTM 기반 오토인코더 사용해 보기
 * 22.3.2 CNN 기반 오토인코더 사용해 보기


## 부록A: 경사하강법에서의 순전파와 역전파
* A.1 예제 신경망 모형
* A.2 순전파
* A.3 역전파
