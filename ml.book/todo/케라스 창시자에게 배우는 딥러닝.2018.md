# 1부 딥러닝의 기초

## 1장 딥러닝이란 무엇인가?
* 1.1 인공 지능과 머신 러닝, 딥러닝
	* 1.1.5 그림 3개로 딥러닝의 작동 원리 이해하기
* 1.2 딥러닝 이전: 머신 러닝의 간략한 역사
	* 1.2.1 확률적 모델링
	* 1.2.2 초창기 신경망
	* 1.2.3 커널 방법
	* 1.2.4 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 머신
	* 1.2.5 다시 신경망으로
	* 1.2.6 딥러닝의 특징

## 2장 시작하기 전에: 신경망의 수학적 구성 요소
* 2.2 신경망을 위한 데이터 표현
	* 2.2.1 스칼라(0D 텐서)
	* 2.2.2 벡터(1D 텐서)
	* 2.2.3 행렬(2D 텐서)
	* 2.2.4 3D 텐서와 고차원 텐서
	* 2.2.5 핵심 속성
	* 2.2.6 넘파이로 텐서 조작하기
	* 2.2.7 배치 데이터
	* 2.2.8 텐서의 실제 사례
	* 2.2.9 벡터 데이터
	* 2.2.10 시계열 데이터 또는 시퀀스 데이터
	* 2.2.11 이미지 데이터
	* 2.2.12 비디오 데이터
* 2.3 신경망의 톱니바퀴: 텐서 연산
	* 2.3.1 원소별 연산
	* 2.3.2 브로드캐스팅
	* 2.3.3 텐서 점곱
	* 2.3.4 텐서 크기 변환
	* 2.3.5 텐서 연산의 기하학적 해석
	* 2.3.6 딥러닝의 기하학적 해석
* 2.4 신경망의 엔진: 그래디언트 기반 최적화
	* 2.4.1 변화율이란?
	* 2.4.2 텐서 연산의 변화율: 그래디언트
	* 2.4.3 확률적 경사 하강법
	* 2.4.4 변화율 연결: 역전파 알고리즘

## 3장 신경망 시작하기
* 3.1 신경망의 구조
	* 3.1.1 층: 딥러닝의 구성 단위
	* 3.1.2 모델: 층의 네트워크
	* 3.1.3 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠
* 3.2 케라스 소개
	* 3.2.1 케라스, 텐서플로, 씨아노, CNTK
	* 3.2.2 케라스를 사용한 개발: 빠르게 둘러보기
* 3.3 딥러닝 컴퓨터 셋팅
	* 3.3.1 주피터 노트북: 딥러닝 실험을 위한 최적의 방법
	* 3.3.2 케라스 시작하기: 두 가지 방법
	* 3.3.3 클라우드에서 딥러닝 작업을 수행했을 때 장단점
	* 3.3.4 어떤 GPU 카드가 딥러닝에 최적일까?
* 3.4 영화 리뷰 분류: 이진 분류 예제
	* 3.4.1 IMDB 데이터셋
	* 3.4.2 데이터 준비
	* 3.4.3 신경망 모델 만들기
	* 3.4.4 훈련 검증
	* 3.4.5 훈련된 모델로 새로운 데이터에 대해 예측하기
	* 3.4.6 추가 실험
	* 3.4.7 정리
* 3.5 뉴스 기사 분류: 다중 분류 문제
	* 3.5.1 로이터 데이터셋
	* 3.5.2 데이터 준비
	* 3.5.3 모델 구성
	* 3.5.4 훈련 검증
	* 3.5.5 새로운 데이터에 대해 예측하기
	* 3.5.6 레이블과 손실을 다루는 다른 방법
	* 3.5.7 충분히 큰 중간층을 두어야 하는 이유
	* 3.5.8 추가 실험
	* 3.5.9 정리
* 3.6 주택 가격 예측: 회귀 문제
	* 3.6.1 보스턴 주택 가격 데이터셋
	* 3.6.2 데이터 준비
	* 3.6.3 모델 구성
	* 3.6.4 K-겹 검증을 사용한 훈련 검증
	* 3.6.5 정리
* 3.7 요약

## 4장 머신 러닝의 기본 요소
* 4.1 머신 러닝의 네 가지 분류
	* 4.1.1 지도 학습
	* 4.1.2 비지도 학습
	* 4.1.3 자기 지도 학습
	* 4.1.4 강화 학습
* 4.2 머신 러닝 모델 평가
	* 4.2.1 훈련, 검증, 테스트 세트
	* 4.2.2 기억해야 할 것
* 4.3 데이터 전처리, 특성 공학, 특성 학습
	* 4.3.1 신경망을 위한 데이터 전처리
	* 4.3.2 특성 공학
* 4.4 과대적합과 과소적합
	* 4.4.1 네트워크 크기 축소
	* 4.4.2 가중치 규제 추가
	* 4.4.3 드롭아웃 추가
* 4.5 보편적인 머신 러닝 작업 흐름
	* 4.5.1 문제 정의와 데이터셋 수집
	* 4.5.2 성공 지표 선택
	* 4.5.3 평가 방법 선택
	* 4.5.4 데이터 준비
	* 4.5.5 기본보다 나은 모델 훈련하기
	* 4.5.6 몸집 키우기: 과대적합 모델 구축
	* 4.5.7 모델 규제와 하이퍼파라미터 튜닝

	
# 2부 실전 딥러닝

## 5장 컴퓨터 비전을 위한 딥러닝
* 5.1 합성곱 신경망 소개
	* 5.1.1 합성곱 연산
	* 5.1.2 최대 풀링 연산
* 5.2 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기
	* 5.2.1 작은 데이터셋 문제에서 딥러닝의 타당성
	* 5.2.2 데이터 내려받기
	* 5.2.3 네트워크 구성하기
	* 5.2.4 데이터 전처리
	* 5.2.5 데이터 증식 사용하기
* 5.3 사전 훈련된 컨브넷 사용하기
	* 5.3.1 특성 추출
	* 5.3.2 미세 조정
	* 5.3.3 정리
* 5.4 컨브넷 학습 시각화
	* 5.4.1 중간층의 활성화 시각화하기
	* 5.4.2 컨브넷 필터 시각화하기
	* 5.4.3 클래스 활성화의 히트맵 시각화하기

## 6장 텍스트와 시퀀스를 위한 딥러닝
* 6.1 텍스트 데이터 다루기
	* 6.1.1 단어와 문자의 원-핫 인코딩
	* 6.1.2 단어 임베딩 사용하기
	* 6.1.3 모든 내용을 적용하기: 원본 텍스트에서 단어 임베딩까지
	* 6.1.4 정리
* 6.2 순환 신경망 이해하기
	* 6.2.1 케라스의 순환 층
	* 6.2.2 LSTM과 GRU 층 이해하기
	* 6.2.3 케라스를 사용한 LSTM 예제
	* 6.2.4 정리
* 6.3 순환 신경망의 고급 사용법
	* 6.3.1 기온 예측 문제
	* 6.3.2 데이터 준비
	* 6.3.3 상식 수준의 기준점
	* 6.3.4 기본적인 머신 러닝 방법
	* 6.3.5 첫 번째 순환 신경망
	* 6.3.6 과대적합을 감소하기 위해 순환 드롭아웃 사용하기
	* 6.3.7 스태킹 순환 층
	* 6.3.8 양방향 RNN 사용하기
	* 6.3.9 더 나아가서
	* 6.3.10 정리
* 6.4 컨브넷을 사용한 시퀀스 처리
	* 6.4.1 시퀀스 데이터를 위한 1D 합성곱 이해하기
	* 6.4.2 시퀀스 데이터를 위한 1D 풀링
	* 6.4.3 1D 컨브넷 구현
	* 6.4.4 CNN과 RNN을 연결하여 긴 시퀀스를 처리하기
	* 6.4.5 정리

## 7장 딥러닝을 위한 고급 도구
* 7.1 Sequential 모델을 넘어서: 케라스의 함수형 API
	* 7.1.1 함수형 API 소개
	* 7.1.2 다중 입력 모델
	* 7.1.3 다중 출력 모델
	* 7.1.4 층으로 구성된 비순환 유향 그래프
	* 7.1.5 층 가중치 공유
	* 7.1.6 층과 모델
	* 7.1.7 정리
* 7.2 케라스 콜백과 텐서보드를 사용한 딥러닝 모델 검사와 모니터링
	* 7.2.1 콜백을 사용하여 모델의 훈련 과정 제어하기
	* 7.2.2 텐서보드 소개: 텐서플로의 시각화 프레임워크
	* 7.2.3 정리
* 7.3 모델의 성능을 최대로 끌어올리기
	* 7.3.1 고급 구조 패턴
	* 7.3.2 하이퍼파라미터 최적화
	* 7.3.3 모델 앙상블
	* 7.3.4 정리
	
## 8장 생성 모델을 위한 딥러닝
* 8.1 LSTM으로 텍스트 생성하기
	* 8.1.1 생성 RNN의 간단한 역사
	* 8.1.2 시퀀스 데이터를 어떻게 생성할까?
	* 8.1.3 샘플링 전략의 중요성
	* 8.1.4 글자 수준의 LSTM 텍스트 생성 모델 구현
	* 8.1.5 정리
* 8.2 딥드림
	* 8.2.1 케라스 딥드림 구현
	* 8.2.2 정리
* 8.3 뉴럴 스타일 트랜스퍼
	* 8.3.1 콘텐츠 손실
	* 8.3.2 스타일 손실
	* 8.3.3 케라스에서 뉴럴 스타일 트랜스퍼 구현하기
	* 8.3.4 정리
* 8.4 변이형 오토인코더를 사용한 이미지 생성
	* 8.4.1 이미지의 잠재 공간에서 샘플링하기
	* 8.4.2 이미지 변형을 위한 개념 벡터
	* 8.4.3 변이형 오토인코더
	* 8.4.4 정리
* 8.5 적대적 생성 신경망 소개
	* 8.5.1 GAN 구현 방법
	* 8.5.2 훈련 방법
	* 8.5.3 생성자
	* 8.5.4 판별자
	* 8.5.5 적대적 네트워크
	* 8.5.6 DCGAN 훈련 방법
	* 8.5.7 정리

## 9장 결론
* 9.1 핵심 개념 리뷰
	* 9.1.1 AI를 위한 여러 방법
	* 9.1.2 머신 러닝 분야에서 딥러닝이 특별한 이유
	* 9.1.3 딥러닝에 대하여
	* 9.1.4 핵심 기술
	* 9.1.5 일반적인 머신 러닝 작업 흐름
	* 9.1.6 주요 네트워크 구조
	* 9.1.7 딥러닝의 가능성
* 9.2 딥러닝의 한계
	* 9.2.1 머신 러닝 모델의 의인화 위험
	* 9.2.2 지역 일반화 vs. 궁극 일반화
	* 9.2.3 정리
* 9.3 딥러닝의 미래
	* 9.3.1 프로그램 같은 모델
	* 9.3.2 역전파와 미분 가능 층을 넘어서
	* 9.3.3 자동화된 머신 러닝
	* 9.3.4 영구 학습과 모듈화된 서브루틴 재사용
	* 9.3.5 장기 비전
* 9.4 빠른 변화에 뒤처지지 않기
	* 9.4.1 캐글의 실전 문제로 연습하기
	* 9.4.2 아카이브(arXiv)를 통해 최신 논문 읽기
	* 9.4.3 케라스 생태계 탐험하기
	
## 부록 A 윈도에 텐서플로와 케라스 설치하기
* A.1 아나콘다 설치하기
* A.2 텐서플로, 케라스 설치하기
* A.3 예제 노트북 실행하기

## 부록 B 우분투 리눅스에 케라스와 필수 라이브러리 설치하기
* B.1 파이썬 과학 라이브러리 설치하기
* B.2 GPU 설정하기
* B.3 씨아노 설치하기(선택 사항)
* B.4 케라스 설치하기
* B.5 아나콘다 환경 파일을 사용하여 설치하기

## 부록 C EC2 GPU 인스턴스에서 주피터 노트북 실행하기
* C.1 주피터 노트북은 무엇일까? 왜 주피터 노트북을 AWS GPU에서 실행할까?
* C.2 딥러닝 주피터 노트북을 위해 AWS를 사용하지 않는 이유는 무엇일까?
* C.3 AWS GPU 인스턴스 설정하기
* C.4 주피터 설정하기
* C.5 케라스 설치하기
* C.6 로컬 포트포워딩 설정하기
* C.7 로컬 브라우저에서 주피터 사용하기
* C.8 코랩을 사용하여 주피터 노트북 실행하기 