## 1장 사용자 수에 따른 규모 확장성
* 단일 서버
* 데이터베이스
* 수직적 규모 확장 vs 수평적 규모 확장
	* 로드밸런서
	* 데이터베이스 다중화
* 캐시
* 콘텐츠 전송 네트워크(CDN)
* 무상태(stateless) 웹계층
	* 상태 정보 의존적 아키텍처
	* 무상태 아키텍처
* 데이터 센터
* 메시지 큐
* 로그, 메트릭, 자동화
* 데이터베이스의 규모 확장
* 백만 사용자, 그 이상
	* 웹 계층은 무상태, 모든 계층에 다중화 도입, 가능한 많은 데이터를 캐시, 여러 데이터 센터 지원, 정적 콘텐츠는 CDN, 데이터 계층은 샤딩을 통해 규모 확장, 각 계층은 독립적 서비스, 시스템을 지속 모니터링하고 자동화 도구 활용


## 2장 개략적인 규모 추정
* 2의 제곱수
* 응답지연 값
	* 메모리는 빠르고 디스크는 느림, 디스크 탐색은 가능한 회피, 단순한 압축 알고리즘 빠름, 데이터를 
* 가용성 수치들
	* 99.99%: 일당 8.64초
* 예제: 트위터 QPS와 저장소 요구량 추정


## 3장 시스템 설계 면접 공략법
	* 뉴스 피드: 피드 publishing, 피드 building
* 문제 이해 및 설계 범위 확정
* 개략적 설계안 제시 및 동의 구하기
* 상세 설계


## 4장 처리율 제한장치의 설계
* 문제 이해 및 설계 범위 확정
	* 요구사항: 제한을 설정, 낮은 응답시간, 적은 메모리 사용, 분산형 처리율 제한(여러 서버/프로세스가 공유), 예외 처리 피드백, 높은 결함 감내성
* 개략적 설계안 제시 및 동의 구하기
	* 처리율 제한 장치의 위치
	* 알고리즘: 토큰 버킷, 누출 버킷, 고정 윈도 카운터, 이동 윈도 로그, 이동 윈도 카운터
* 상세 설계
* 마무리


## 5장 안정해시 설계
* 해시 키 재배치(rehash) 문제
* 안정 해시
	* 해시 테이블 크기가 조정될 때 최소한의 키만 재배치하는 해시 기술
	* 해시 공간과 해시 링, 해시 서버, 해시 키, 서버 조회, 서버 추가, 서버 제거
	* 기본 구현법의 두 가지 문제, 가상 노드, 재배치할 키 결정


## 6장 키-값 저장소 설계
* 문제 이해 및 설계 범위 확정
	* 키-값 크기, 큰 데이터 수용, 높은 가용성, 높은 규모 확장성, 데이터 일관성 수준 조정 가능, 응답 지연시간 짧음
* 단일 서버 키-값 저장소
	* 키-값 쌍 전무를 메모리에 해시 테이블로 저장
* 분산 키-값 저장소
	* 분산 해키 테이블: 키-값 쌍을 여러 서버에 분산
	* CAP 정리: CAP를 동시에 만족하는 분산 시스템은 불가능, 셋 중 하나는 반드시 희생
		* 일관성(consistency): 어느 노드에 접속해도 같은 데이터 표시
		* 가용성(availability): 일부 노드에 장애가 발생해도 항상 응답 가능
		* 파티션 감내(partition tolerance): 파티션(두 노드 사이에 통신 장애 발생)이 생기더라도 시스템은 계속 동작
	* CP 시스템: 일관성, 파티션 감내를 지원, 가용성 희생
	* AP 시스템: 가용성과 파티션 감내를 지원, 데이터 일관성 희생
	* CA 시스템: 일관성과 가용성 지원, 파티션 감내를 희생
		* 네트워크 장애는 회피 불가하므로 분산시스템은 반드시 파티션 감내 가능해야 하므로
			* 실세계에서 CA 시스템은 존재하지 않음
	* 시스템 컴포넌트: 다이나모, 카산드라, 빅테이블 사례 참고
		* 데이터 파티션
			* 데이터를 여러 서버에 고르게 분산할 수 있는가
			* 노드가 추가되거나 삭제될 때 데이터 이동을 최소화할 수 있는가
			* 안정 해시
				* 규모 확장 자동화
				* 다양성(heterogeneity): 각 서버 용량에 맞게 가상 노드 개수 조정
		* 데이터 다중화(replication)
		* 일관성
			* 정족수 합의(quorum consensus) 프로토콜
			* 일관성 모델: 강한 일관성, 약한 일관성, 최종 일관성
		* 일관성 불일치 해소
			* 데이터 버저닝: 데이터 변경시 새 버전 생성, 각 버전 데이터는 변경 불가(immutable)
		* 장애 처리
			* 장애 처리, 장애 감지, 영구 장애 처리
		* 시스템 아키텍처 다이어그램
			* 클라이언트는 키-값 저장소가 제공하는 get, put api 와 통신
			* 중재자는 proxy 역할을 하는 노드
			* 노드는 안정 해시의 해시 링 위에 분포
			* 노드를 자동으로 추가/삭제할 수 있도록 시스템은 완전 분산
			* 데이터는 여러 노드에 다중화, SPOF(single point of failure)는 존재하지 않음
		* 쓰기 경로(write path)
			* 쓰기 요청이 커밋 로그에 기록
			* 데이터가 메모리 캐시에 기록
			* 메모리 캐시가 가득차거나 임계치에 도달하면 데이터를 디스크의 SSTable(sorted-string table) 에 기록
		* 읽기 경로(read path)
			* 데이터가 메모리에 있는지 검사
			* 없으면 블룸 필터를 검사하여 어떤 SSTable에 키가 보관되어 있는지 확인하여 데이터를 가져온 후 클라이언트에 반환
* 요약
	* 대규모 데이터 저장: 안정 해시를 사용해 서버들에 부하 분산
	* 읽기 연산 가용성: 데이터를 여러 데이터 센터에 다중화
	* 쓰기 연산 가용성: 버저닝 및 벡터 시계를 사용한 충돌 해소
	* 데이터 파티션: 안정 해시
	* 점진적 규모 확장성: 안정 해시
	* 다양성(heterogeneity): 안정 해시
	* 조절 가능한 데이터 일관성: 정족수 합의(quorum consensus)
	* 일시적 장애 처리: 느슨한 정족수 프로토콜(sloppy quorum)과 단서 후 임시 위탁(hinted handoff)
	* 영구적 장애 처리: 머클 트리(merkle tree)
	* 데이터 센터 장애 대응: 여러 데이터 센터에 걸친 데이터 다중화


## 7장 분산시스템을 위한 유일 ID 생성기 설계
* 문제 이해 및 설계 범위 확정
	* RDB auto increment: 여러 DB 서버를 사용해도 지연시간 문제
	* 유일, 숫자, 64비트, 시간 정렬, 초당 10,000개 생성
* 개략적 설계안 제시 및 동의 구하기
	* 다중 마스터 복제(multi-master replication)
		* DB의 auto_increment 기능 활용, 증가 폭이 1이 아니라 DB 서버 수
	* UUID
		* 충돌 가능성이 지극히 낮으므로 서버 간 조욜 없이 생성 가능
		* 단점: 128비트로 길고 시간순 정렬 불가, 숫자 아닌 값 포함됨
	* 티켓 서버
		* auto_increment를 단일 서버에서 발행: 티켓 서버가 SPOF
	* 트위터 스노플레이크 접근법
		* 요구사항 충족
		* 64비트 id 구조: sign 1 bit + 타임스탬프 41 bit + 데이터센터 id 5 bit + 서버 id 5 bit + 일련번호 12 bit
* 상세 설계
	* 기타: 시계 동기화, 길이 최적화, 고가용성


## 8장 URL 단축기 설계
* 문제 이해 및 설계 범위 확정
* 개략적 설계안 제시 및 동의 구하기
	* api 엔드포인트: post 요청
	* URL 리디렉션: get 요청
		* 응답: 301(moved)은 브라우저에서 캐시됨(서버 부하 감소), 302(found)는 분석/추적에 유리
		* 해시 테이블에 단축 url, 오리지널 url 저장
		* 실제 시스템에서는 RDB에 페어를 저장
* 상세 설계
	* 해시 함수 구현
		* 해시 후 충돌 해소: 원본 url 길이를 7글자까지 줄인 후(CRC32, MD5, SHA-1)
			* 길이 고정됨, 유일성 보장 id 생성기 불필요, 충돌 해소 전략 필요, id로 단축 url을 계산하지 않으므로 다음 생성 가능한 url 추정 불가
		* base-62 변환
			* 길이 가변적, 유일성 보장 id 생성기 필요, 충돌 불가, 다음 생성할 단축 url 유추 가능


## 9장 웹크롤러 설계
	* 사례: 검색 엔진 인덱싱, 웹 아카이빙, 웹 마이닝, 웹 모니터링
* 문제 이해 및 설계 범위 확정
	* 기본 알고리즘
		* url 집합 입력, 해당 url들이 가리키는 모든 페이지를 다운로드
		* 다운받은 페이지에서 url들을 추출
		* 반복
	* 고려: 규모 확장성(병행성), 안정성, 예절, 확장성
	* 규모 측정: QPS는 매달 10억개 페이지일 경우 초당 400페이지
* 개략적 설계안 제시 및 동의 구하기
	* 시작 url 집합
	* 미수집 url 저장소
	* html 다운로더
	* 도메인 이름 변환기
	* 콘텐츠 파서
	* 중복 콘텐츠 제거: 웹 페이지 해시 값 비교
	* 콘텐츠 저장소
	* url 추출기
	* url 필터
	* 이미 방문한 url: 블룸 필터나 해시 테이블
	* url 저장소
* 상세 설계
	* DFS(depth-first search) vs BFS(breath-first search)
		* 웹은 유향(directed) 그래프: 페이지는 node, 링크는 edge
		* 깊이 우선 탐색은 not good, 보통 너비 우선 탐색법
		* BFS는 FIFO 큐 사용
			* 문제
				* 페이지 내 상당수 링크는 동일 서버: 예의 없는 크롤링: DoS
				* 표준 BFS는 url 간 우선순위 없음
	* 미수집 url 저장소
		* 예의 갖춘 크롤링, url 우선순위와 신선도 구별
		* 동일 사이트에는 한번에 한 페이지만 요청: 호스트명과 작업 스레드 간 관계 유지
			* 큐 라우터: 같은 호스트의 url이 언제나 같은 큐로 가도록 보장
			* 매핑 테이블: 호스트명과 뮤 사이의 관계를 보관
			* FIFO 큐: 동일 호스트의 url은 동일 큐에 보관
			* 큐 선택기: 큐들을 순회하여 큐에서 url을 꺼내 지정된 작업 스레드에 전달
			* 작업 스레드: 순차적 처리, 작업들 간 지연시간 둘 수 있음
		* 우선순위
			* 페이지랭크, 트래픽 양, 갱신 핀도
			* 순위결정장치(prioritizer)
		* 전면 큐: 우선순위 결정 과정 처리
		* 후면 큐: 예의 작동 보증
		* 신선도: 재수집(recrawl)
			* 페이지 변경 이력 활용, 우선순위 높은 페이지는 재수집 빈도 높임
		* 지속성 저장장치
			* 병목지점 가능성 절충안: 대부분 url은 디스크에 두고 메모리 버퍼에 큐를 배치
	* html 다운로더
		* 로봇 프로토콜
		* 성능 최적화
			* 분산 크롤링: 여러 서버에 작업을 분산, 각 서버에서 여러 스레드 작동
			* 도메인 이름 변환 결과 캐시(주기적 갱신): dns resolver는 크롤러 성능 병목 중 하나
			* 지역성: 크롤링 대상과 지역적으로 가깝게
			* 짧은 타임아웃
	* 안정성
		* 안정 해시, 크롤링 상태 및 수집 데이터 저장(장애 발생시 복구), 예외 처리, 데이터 검증
	* 확장성
		* 새로운 모듈을 추가하여 새 형색의 콘텐츠 지원
	* 문제 콘텐츠 감지 및 회피 전략
		* 중복 콘텐츠, 거미 덫(spider trap, 크롤러를 무한 루프시킴)
		* 데이터 노이즈: 가치없음, 광고/스팸/스크립트
* 기타
	* 서버사이드 렌더링: 페이지를 파싱하기 전 적용
	* 스팸방지 컴포넌트 배치
	* 데이터베이스 다중화 및 샤딩
	* 수평적 규모 확장성: 서버가 상태정보를 유지하지 않도록(무상태 서버)
	* 가용성, 일관성, 안정성
	* 데이터 분석 솔루션


## 10장 알림 시스템 설계
* 문제 이해 및 설계 범위 확정
	* 푸시/SMS/이메일, soft real-time, mobile/pc
* 개략적 설계안 제시 및 동의 구하기
	* 유형별
		* ios: provider(device token, payload), APNS, 단말
		* android: provider, FCM, 단말
	* 전송 및 수신 절차
		* 컴포넌트 초안: 서비스 N개, 알림 시스템, 서드파티 서비스
			* SPOF, 규모 확장성, 성능 병목
		* 개선안: DB와 캐시를 알림 시스템 주 서버에서 분리, 수평적 규모 확장 가능하게, 메시지 큐를 이용해 강결합 제거
			* 서비스 N개: 알림을 보낼 서비스들
			* 알림 서버: 알림 전송 api, 알림 검증, DB 혹은 캐시 질의(알림 데이터 획득)
			* 알림 전송: 메시지 큐에 추가(병렬적)
				* 작업 서버(workers): 메시지 큐에서 알림을 추출하여 서드파티 서비스로 전달
		* 진행
			* api 호출, 알림서버로 알림 전달
			* 알림 서버는 사용자 정보, 단말 토큰, 알림 설정 등 메타데이터를 캐시나 DB에서 획득
			* 알림 서버는 전송할 알림에 맞는 이벤트를 만들어서 해당 이벤트를 위한 큐에 추가
			* 작업 서버는 메시지 큐에서 알림 이벤트 꺼냄, 작업 서버는 알림을 서드파티 서비스로 전달
			* 서드 파티 서비스는 사용자 단말로 알림 전송
* 상세 설계
	* 안정성
		* 소실 방지(데이터 보관, 로그, 재시도): 지연/순서 변경은 허용
		* 중복 전송 감소를 위한 중복 탐지
	* 기타: 알림 템플릿, 알림 설정, 전송률 제한, 재시도 방법
	* 푸시 알림과 보안: api: appKey, appSecret
	* 큐 모니터링
	* 이벤트 추적: 알림 확인율, 클릭율, 전환율


## 11장 뉴스피드 시스템 설계
* 문제 이해 및 설계 범위 확정
	* 모바일/웹, 추가/열람, 순서(최신/순위), 친구 최대 수, 트래픽(DAU), 미디어(오디오/비디오) 포함 여부
* 개략적 설계안 제시 및 동의 구하기
	* 피드 발행(publishing)
		* 작성자, api(post), 로드밸런서, 웹서버, 포스팅 저장소(DB/캐시), 포스팅 전송 서비스(친구의 피드에 푸시), 알림 서비스
	* 피드 생성(building)
		* 열람자, api(get), 로드밸런서, 웹서버, 피드 서비스(캐시에서 피드를 획득), 피드 캐시(피드를 렌더링할때 필요한 피드 id를 보관)
* 상세 설계
	* 웹 서버: 클라이언트 통신, 인증(Authorization 헤더), 처리율 제한
	* 포스팅 전송(팬아웃(fanout): 새 포스팅을 친구들에게 전달) 서비스
		* 쓰기 시점 팬아웃(fanout-on-write, push 모델)
			* 실시간 갱신, pre-computed, 피드 읽기 시간 감소
			* 친구 많을 경우 갱신 소요 시간(hotkey), 비활성자 자원 낭비
		* 읽기 시점 팬아웃(fanout-on-read, pull 모델)
			* on-demand, 비활성자 효율, hotkey 이슈 없음
			* 피드 읽기 소요 시간 증가
	* 개선
		* 다수 사용자에게 push 모델, 친구가 많은 경우에 pull 모델
		* 안정 해시로 요청과 데이터를 고르게 분산
		* 팬아웃 서비스
			* 그래프 DB에서 친구 id 목록 획득
			* 사용자 정보 캐시에서 친구들 정보 획득: 설정으로 필터링(mute, private 등)
			* 친구 목록과 새 포스팅을 메시지 큐에 추가
			* 팬아웃 작업 서버가 메시지 큐에서 데이터를 꺼내어 피드 데이터를 피드 캐시에 추가
				* 피드 캐시: 포스팅 id, 사용자 id 페어를 보관하는 매핑 테이블
					* 새 포스팅 생성시마다 피드 캐시에 레코드 추가
					* 캐시 크기 제한
		* 피드 읽기
			* 피드 읽기 요청, 로드밸런서가 요청을 웹서버로 전달
			* 웹 서버는 피드 서비스 호출
			* 피드 서비스는 피드 캐시에서 포스팅 id 목록을 획득
			* 피드에 표시할 사용자 데이터(이름/사진/콘텐츠/이미지)를 사용자 캐시와 포스팅 캐시에서 가져와 완전한 피드 생성
			* 생성된 피드를 클라이언트에 반환(json), 클라이언트 렌더링
		* 캐시 구조: 캐시는 피드 시스템의 핵심 컴포넌트
			* 피드(피드 id 보관)
			* 콘텐츠: 인기, 일반
			* 소셜 그래프: 팔로어, 팔로잉
			* 행동: 좋아요, 답글, 기타
			* 횟수: 좋아요, 답글, 기타
* 기타
	* DB 규모 확장: 수직/수평, SQL/NoSQL, master/slave 다중화, replica 읽기 연산, 일관성(consistency) 모델, DB 사딩
	* 웹 계층 무상태 운영, 가능한 많은 데이터 캐시, 여러 데이터 센터 지원, 메시지 큐로 컴포넌트 결합도 낮추기, 핵심 메트릭(ex: 트래픽 높은 시간대의 QPS(queries per second)) 모니터링, 피드 새로고침시 지연시간


## 12장 채팅 시스템 설계
* 문제 이해 및 설계 범위 확정
	* 일대일/다대다, 모바일/웹, DAU 5천만, 그룹 100명, 기능(첨부/상태표시), 메시지 길이 제한, 종단 간 암호화(end-to-end encryption), 보관 기간
	* 응답지연 낮음, 다수 단말 지원, 푸시 알림
* 개략적 설계안 제시 및 동의 구하기
	* 클라이언트는 서로 직접 통신하지 않음, 클라이언트는 채팅 서비스와 통신
	* 채팅 서비스
		* 클라이언트들로부터 메시지 수신
		* 메시지 수신자(recipient) 결정 및 전달
		* 수신자가 오프라인일 경우 접속할 때까지 해당 메시지 보관
	* http
		* 클라이언트가 채팅서비스에 http 연결, keep-alive 헤더(handshake 감소)
		* 메시지 전송 용도로는 양호, 초기 서비스에 사용
		* 메시지 수신 용도로는 복잡
			* polling: 주기적 문의, 비효율
			* long polling: 클라이언트는 결과를 획득하거나 타임아웃 될때까지 연결 유지, 반복
				* http 서버들이 무상태일때 수신/발신 대상 서버가 다를 수 있음(로그밸런싱 라운드로빈)
				* 서버는 클라이언트가 연결을 해제했는지 알수 없음
				* 비효율
			* 웹소켓
				* 클라이언트가 연결 시작, 연결은 항구적/양방향
				* 시작은 http 연결이지만 특정 handshake 절차를 거쳐 웹소켓 연결로 전환
				* 80 혹은 443 포트를 그대로 사용하므로 방화벽 무관
	* 개략적 설계
		* 무상태 서비스: 로드밸런서 뒤에 위치, 서비스탐색/인증/그룹관리/사용자 프로파일
			* 서비스 탐색(service discovery): 접속할 채팅 서버 호스트명을 클라이언트에 전달
		* 상태 유지 서비스: 채팅 서비스: 클라이언트는 서버가 살아 있는 한 다른 서버로 연결 변경하지 않음
		* 서드파티 서비스: 푸시 알림
		* 규모 확장성: 접속당 10k 메모리 필요시 동접 1M을 10GB 메모리로 처리, SPOF
			* 채팅 서버: 클라이언트 사이의 메시지 중계
			* 접속상태 서버: 사용자 접속 여부 관리
			* api 서버: 로그인/가입/프로파일 변경 등
			* 알림서버: 푸시 알림
			* 키-값 저장소: 채팅 이력 보관
		* 저장소
			* 일반적 데이터(사용자 프로필, 설정, 친구 목록): RDB, 다중화, 샤딩
			* 채팅 고유 데이터: 채팅 이력(history): 키-값 저장소
				* 데이터 양 매우 큼, 최근 메시지가 빈번히 사용, 일대일 채팅의 경우 읽기/쓰기 비율은 1:1
				* 키-값 저장소는 수평적 규모확장이 용이, 데이터 접근 지연시간 낮음, 롱테일 처리, 선행 사례(페이스북 HBase, 디스코드 Cassandra)
		* 데이터 모델
			* 일대일 채팅: 기본키는 메시지 아이디
			* 그룹 채팅: 복합키는 채널 아이디와 메시지 아이디
			* 메시지 아이디는 순서 표현 가능해야: 고유성, 정렬 가능/시간 순서 일치
				* 전역적 혹은 지역적 순서 번호 생성기 필요
* 상세 설계
	* 서비스 탐색: 클라이언트에게 가장 적합한 채팅 서버 추천
		* 기준: 클라이언트 위치, 서버 용량
		* api 서버가 사용자 인증을 처리한 후 서비스 탐색 기능 작동
		* 솔루션: apache zookeeper
	* 메시지 흐름
		* 일대일
			* 사용자 A가 채팅 서버 1로 메시지 전송
			* 채팅 서버 1은 id 생성기 사용해 해당 메시지 id 결정
			* 채팅 서버 1은 해당 메시지를 메시지 동기화 큐로 전송
			* 메시지가 키-값 저장소에 보관됨
			* 사용자 B가 접속 중인 경우 메시지는 사용자 B가 접속 중인 채팅 서버 2로 전송됨
				* 사용자 B가 접속 중이 아닌 경우 푸시 알림 메시지를 푸시 알림 서버로 전송
			* 채팅 서버 2는 메시지를 사용자 B에게 전송(웹소켓 연결)
		* 단일사용자의 다수 단말 간 메시지 동기화
			* 각 단말별 cur_max_message_id 값 유지
				* 수신자 아이디가 로그인한 사용자 아이디이고, 키-값 저장소에 보관된 메시지의 아이디가 cur_max_message_id 보다 크면 새 메시지로 간주
		* 그룹 채팅(소규모): 500명 제한(WeChat)
			* 사용자 A가 보낸 메시지가 사용자 B, C의 메시지 동기화 큐에 복사됨(사용자별 메시지 수신함 개념)
			* 새 메시지 확인은 각자의 큐만 확인: 메시지 동기화 간단
			* 소규모 그룹은 메시지를 수신자별로 복사해서 큐에 추가하는 비용이 적음
		 	* 한 수신자(의 메시지 동기화 큐)는 여러 사용자로부터의 메시지를 수신할 수 있어야
	* 접속 상태 표시
		* 접속 상태 서버도 클라이언트와 웹소켓 통신
		* 상태 변경
			* 로그인, 로그아웃
			* 접속 장애: 너무 빈번한 변경을 회피
				* 온라인 클라이언트가 주기적으로 heartbeat 이벤트를 서버로 전송
		* 상태 정보의 전송
			* 상태정보 서버는 발행-구독(publish-subscribe) 모델 사용
				* 각각의 친구관계마다 채널을 배치, 사용자 A의 접속상태 변경시 채널 3개(A-B, A-C, A-D)에 write
				* 클라이언트-서버 간 웹소켓
				* 그룹 크기 작을 때 유용(WeChat, 500명)
			* 그룹 크기 클 경우
				* 사용자가 그룹 채팅에 입장하는 순간에만 상태 정보를 읽도록, 혹은 개별 친구 상태 정보를 수동 갱신하도록 유도
* 기타
	* 미디어(이미지, 비디오) 지원: 압축, 저장소, 섬네일
	* 종단 간 암호화
	* 캐시(클라이언트)
	* 로딩 속도 개선: 슬랙의 지역 분산 네트워크
	* 오류 처리
		* 채팅 서버 오류: 서비스 탐색 기능이 동작하여 클라이언트에게 새 서버 배정 후 재접속
		* 매시지 재전송: retry 혹은 큐



## 13장 검색어 자동완성 시스템
* 문제 이해 및 설계 범위 확정
	* 사용자 입력단어의 자동완성 검색어 내 위치(첫, 중간)
	* 기준(인기(질의 빈도) 순위 등), 개수
	* 맞춤법/자동수정 지원 여부
	* 영어, 다국어
	* 대문자/특수문자 지원 여부
	* DAU 천만
	* 요구사항
		* 빠른 응답 속도: 100밀리초 이내
		* 연관성
		* 정렬: 인기도(popularity) 등 순위 모델로 정렬
		* 규모 확장성, 고가용성
	* 규모 측정
		* DAU 천만, 1 사용자 당 매일 10건 검색
		* 질의 1회 당 20바이트 입력: 5글자 단어 4개: 1바이트 문자(ASCII) 가정
		* 글자 입력시 백엔드에 요청: 1회 검색당 20건 요청
			* 초당 24,000건 질의(QPS) 발생
			* 최대 QPS = 평균 QPS x 2 = 48,000
		* 질의 중 20%는 신규 검색어: 매일 0.4GB 신규 데이터 추가됨
* 개략적 설계안 제시 및 동의 구하기
	* 데이터 수집(data gathering) 서비스: 사용자 질의를 실시간 수집
	* 질의(query) 서비스: 주어진 질의에 인기 검색어 5개 정렬해서 반환
		* 빈도(frequency) 테이블: 질의문과 사용빈도를 저장
			* 컬럼: query(질의문 저장), frequeycy(빈도 저장)
			* 데이터 증가하면 DB 병목
* 상세 설계
	* 트라이(trie) 자료구조
		* RDB 비효율 대안
		* 문자열들을 간략히 저장/추출하는 자료구조, 어원은 retrieval, 트리 형태
		* 각 노드는 character 하나를 저장, 26개(해당 글자 다음에 등장 가능한 모든 글자 개수)의 자식 노드 가능
		* 각 트리 노드는 하나의 단어 또는 접두어 문자열(prefix string)을 나타냄
			* 접두어 길이, 트라이 내부 노드 개수, 주어진 노드의 자식 노드 개수
		* 가장 많이 사용된 질의어
			* 해당 접두어 표현 노드 찾음
			* 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드 찾음
			* 유효 노드들을 정렬하여 가장 인기있는 검색어 k개 찾음
		* 최악 회피
			* 접두어 최대 길이 제한
			* 각 노드에 인기 검색어를 캐시
	* 데이터 수집 서비스
		* 사용자 입력 타이핑시마다 데이터 수정은 비실용적
		* 데이터 분석 서비스 로그
		* 로그 취합 서버, 취합된 데이터, ex)일주일 주기 취합
		* 작업 서버: 주기적 비동기 작업 실행: 트라이 자료구조 생성, 트라이 DB에 저장
		* 트라이 캐시: 트라이 데이터를 메모리에 유지
		* 트라이 DB
			* 문서 저장소(document store)
				* 새 트라이를 매주 생성, 주기적으로 트라이를 직렬화하여 DB에 저장, mongoDB
			* 키-값 저장소: 해시테이블 형태로 변환 가능
				* 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
				* 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환
	* 질의 서비스
		* 개선안
			* 검색 질의가 로드밸런서로 전송, 해당 질의가 api 서버로 전달됨
			* api 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답 구성
			* 데이터가 트라이 캐시에 없는 경우 DB 이용 및 캐시에 반영(cache miss)
			* 클라이언트 속도
				* 비동기 화면 갱신, 브라우저 캐싱
				* 데이터 샘플링: 대규모시 로깅은 낭비, 다수 요청 중 1개만 로깅
	* 트라이 연산
		* 트라이 생성: 작업 서버가 담당
		* 트라이 갱신: 주기적(기존 트라이 대체), 혹은 각 노드를 개별적으로 갱신(성능이 나쁘며 작을때 고려 가능)
	* 규모 확장이 가능한 저장소
		* 큰 트라이: 첫 글자 기준으로 샤딩
* 기타
	* 다국어 지원: 트라이에 유니코드 저장
	* 단위(ex: 국가별) 인기 검색어 순위 차이: 단위별 다른 트라이, CDN 저장
	* 실시간 트랜드: 작업 서버 주기가 주당 1회이면 적절하지 않음, 고비용
	* 샤딩을 통해 분량 감소
	* 순위 모델: 최근 검색어에 높은 가중치
	* 스트림 데이터 가능성 고려: apache hadoop mapReduce, apache spark streaming, apache storm, apache kafka



## 14장 유튜브 설계
* 문제 이해 및 설계 범위 확정
	* ex) 유튜브: MAU 20억, 일당 재생 수 50억, 모바일 트래픽 37% 점유
	* 비디오 업로드/시청
	* DAU 500만, 인당 일간 30분 소비/5개 비디오 시청, 10% 사용자가 일간 1개 비디오 업로드
	* 비디오 크기 300MB, 일간 150TB 필요, CDN 비용, 
	* 다국어, 다수 비디오/해상도 지원, 크기 제한
	* 암호화 지원, 클라우드 서비스 활용 가능
	* 빠른 업로드, 원활한 재생, 재생 품질 선택, 낮은 인프라 비용, 가용성/확장성/안정성, 다수 플랫폼 지원
* 개략적 설계안 제시 및 동의 구하기
	* CDN, BLOB: 클라우드 서비스 활용
	* 구성: 사용자 단말, api 서버(피드 추천, 업로드 url 생성, 메타데이터/캐시 갱신, 가입 등), CDN(스트리밍)
	* 비디오 업로드 절차
		* 컴포넌트
			* 사용자
			* 로드밸런서: api 서버 각각으로 고르게 요청 분산
			* api 서버
			* 메타데이터 DB: 샤딩/다중화
			* 메타데이터 캐시
			* 원본 저장소(original storage): BLOB
			* 트랜스코딩 서버: 비디오 인코딩
			* 트랜스코딩 비디오 저장소: BLOB
			* CDN
			* 트랜스코딩 완료 큐(completion queue): 비디오 트랜스코딩 완료 이벤트들을 보관할 메시지 큐
			* 트랜스코딩 완료 핸들러(completion handler): 트랜스코딩 완료 큐에서 이벤트 데이터를 꺼내어 메타데이터 캐시와 DB를 갱신할 작업 서버들
		* 프로세스: 아래 2개가 병렬 수행
			* 비디오 업로드
				* 비디오를 원본 저장소에 업로드
				* 트랜스코딩 서버는 원본 저장소에서 해당 비디오를 가져와 트랜스코딩, 완료되면 아래 절차를 병렬 실행
					* 완료된 비디오를 트랜스코딩 비디오 저장소로 업로드
					* 트랜스코딩 완료 이벤트를 트랜스코딩 완료 큐에 추가
						* 트랜스코딩 완료된 비디오를 CDN에 추가
						* 완료 핸들러가 이벤트 데이터를 큐에서 꺼냄
						* 완료 핸들러가 메타데이터 DB와 캐시를 갱신
					* api 서버가 단말에게 비디오 업로드 완료 및 스트리밍 준비됨을 알림
			* 비디오 메타데이터(url, 크기, 해상도, 포맷, 사용자 정보) 갱신
				* 원본 저장소에 파일이 업로드되는 동안 단말은 병렬적으로 비디오 메타데이터 갱신 요청을 api 서버로 보냄
	* 비디오 스트리밍 절차
		* 스트리밍 프로토콜: MPEG-DASH, Apple HLS, MS Smooth Streaming, Adobe HDS
* 상세 설계
	* 비디오 트랜스코딩
		* 공간 절약, 단말별 포맷들 지원(호환성), 접속 환경별 (가변적)품질
		* 인코딩 포맷: 컨테이너(파일 확장자), 코덱(압축/해제 알고리즘)
	* 유향 비순환 그래프(DAG(directed acyclic graph))모델
		* 원본 비디오: 비디오, 오디오, 메타데이터로 분리 처리
			* 비디오: 검사, 인코딩, 섬네일, 워터마크
	* 비디오 트랜스코딩 아키텍처
		* 전처리기
			* 비디오 분할, DAG 생성, 데이터 캐시
		* DAG 스케줄러
			* DAG 그래프를 몇 개 단계로 분할하여 자원관리자 작업 큐에 추가
		* 자원관리자(resource manager)
			* 작업 큐/작업서버 큐/실행 큐, 작업 스케줄러
		* 작업 실행 서버(resource worker)
		* 임시 저장소
	* 시스템 최적화
		* 속도: 비디오 병렬 업로드, 업로드 센터를 사용자 근거리에 지정, 모든 절차를 병렬화(ex: 메시지 큐)
		* 안정성: 미리 사인된 업로드 url, 비디오 보호(DRM, AES 암호화, 워터마크)
		* 비용
			* 유튜브 사례에서 비디오는 롱테일: 인기 비디오는 CDN/비인기 비디오는 비디오 서버, 필요할 때 인코딩
			* 지역성
	* 오류 처리: highly fault-tolerant
		* 회복 가능(recoverable) 오류, 회북 불가능(non-recoverable) 오류
		* 오류 사례: 업로드, 비디오 분할, 트랜스코딩, 전처리, DAG 스케줄러, 자원관리자 큐, 작업 서버, api 서버, 메타데이터 캐시 서버, 메타데이터 DB
* 기타
	* api 계층 규모 확장성
	* DB 계층 규모 확장성
	* 라이브 스트리밍
	* 비디오 삭제


## 15장 구글드라이브 설계
* 문제 이해 및 설계 범위 확정
	* 범위
		* 업/다운로드, 동기화, 알림
		* 모바일/웹
		* 암호화
		* 크기 제한 10GB, DAU 천만
	* 기능
		* 파일 추가(드롭 다운), 다운로드
		* 여러 단말에 파일 동기화
		* 파일 갱신 이력 조회(revision history)
		* 파일 공유
		* 편집/삭제/공유시 알림 표시
	* 제외: 편집/협업
	* 비기능
		* 안정성/빠른 동기화/사용 대역폭/규모 확장성/높은 가용성
	* 추정
		* 가입자 5천만, DAU 천만
		* 사용자당 10GB 공간, 인당 일일 2개 파일 업로드, 파일 개당 500kb, 읽기/쓰기 비율은 일대일
		* 저장공간 총량 500페타바이트, 업로드 api QPS 240, 최대 QPS 480
* 개략적 설계안 제시 및 동의 구하기
	* 단일 서버 구현
		* 업로드/다운로드 처리하는 웹서버
			* api: 업로드, 다운로드, 갱신 히스토리
				* 업로드: 단순 업로드, 이어 올리기(resumable upload)
					* 이어 올리기: url을 받기 위한 최초 요청
					* 데이터 업로드 후 모니터링
					* 업로드 장애시 장애발생시점부터 업로드 재시작
		* 메타데이터 DB
			* 로드밸런서, 웹서버
		* 파일 저장 시스템
			* 공간 이슈: 데이터 샤딩, AWS S3(다중화)
	* 동기화 충돌
		* 먼저 처리되는 변경은 성공, 나중에 처리되는 변경은 충돌로 표시
	* 개략적 설계
		* 사용자 단말
		* 블록 저장소 서버, 클라우드 저장소, 아카이빙 저장소
		* 로드배런서, api 서버
		* 메타데이터 데이터베이스, 메타데이터 캐시
		* 알림 서비스
		* 오프라인 사용자 백업 큐
* 상세 설계
	* 블록 저장소 서버
		* 대역폭 소모 문제
			* 델타 동기화(delta sync): 전체 파일 대신 수정된 블록만 동기화
			* 압축: 블록 단위로 압축
		* 새 파일 추가시
			* 주어진 파일을 블록들로 분할, 각 블록들을 압축
			* 암호화 후 클라우드 저장소로 전송
	* 높은 일관성 요구사항
		* 강한 일관성(strong consistency) 보장해야, 캐시는 보통 최종 일관성(eventual consistency)까지만 제공
			* 캐시 사본과 DB 원본 일치, DB 원본 변경시 캐시 사본 무효화
			* RDB는 ACID 보장하나 NoSQL은 동기화 추가해야, 사례에서는 RDB 사용
	* 메타데이터 DB
		* 스키마
			* user
			* device
			* namespace: 사용자 루트 디렉토리 정보 보관
			* file: 파일의 최신 정보
			* file_version: 추가되는 레코드는 읽기 전용
			* block: 파일 블록 정보 보관, 파일 버전 아이디/블록 순서 포함, 파일 버전 복원에 활용
	* 업로드/업데이트 절차: 병렬 전송
		* 파일 메타데이터 추가
			* 클라이언트가 새 파일 메타데이터 추가를 위해 요청
			* 새 파일 메타데이터를 DB에 저장 후 업로드 상태를 pending 으로 변경
			* 새 파일 추가됨을 알림 서비스에 통지
			* 알림 서비스는 해당 클라이언트에게 업로드 결과를 알림
		* 파일을 클라우드 저장소로 업로드
			* 클라이언트가 파일을 블록 저장소 서버에 업로드
			* 블록 저장소 서버는 파일을 블록 단위로 분리/압축/암호화 후 클라우드 저장소로 전송
			* 업로드 후 클라우드 스토리지는 완료 콜백으로 api 서버 호출
			* 메타데이터 DB에 기록된 해당 파일의 상태를 완료로 변경
			* 알림 서비스에 파일 업로드 완료 통지, 알림 서비스는 해당 클라이언트에 알림
	* 다운로드 절차
		* 파일이 추가/갱신되면 자동으로 시작됨
			* (온라인/오프라인)클라이언트에게 알림 필요: 알림 서비스가 클라이언트 혹은 캐시에게 전송
		* 변경 감지한 클라이언트는 api 서버를 통해 메타데이터 확보한 후, 블록들을 다운받아 파일 재구성
		* 흐름
			* 알림 서비스가 클라이언트에게 파일 변경 알림
			* 클라이언트는 새 메타데이터 요청
			* api 서버는 메타데이터 DB에 새 메타데이터 요청 및 획득
			* 클라이언트에게 새 메타데이터 반환, 클라이언트는 블록 다운로드 요청
			* 블록 저장소 서버는 클라우드 저장소에서 블록 다운로드
			* 클라우드 저장소는 블록 서버에 요청된 블록 반환
			* 블록 저장소 서버는 클라이언트에게 블록 반환, 클라이언트는 블록을 파일로 재구성
	* 알림 서비스
		* 사례
			* 롱 폴링: 드롭박스 사례
			* 웹 소켓: 양방향
		* 양방향 통신은 불필요하므로 롱 폴링
			* 클라이언트는 알림 서버와 롱 폴링 연결 유지, 특정 파일 변경 감지시 연결 끊김
				* 클라이언트는 메타데이터 서버와 연결해 파일의 최신 내역 다운로드
				* 다운로드 완료 혹은 연결 타임아웃 도달시 새 요청으로 롱 폴링 연결 복원/유지
	* 저장소 공간 절약
		* 중복 제거(de-dupe): 중복된 파일 블록을 계정 차원에서 제거(해시값 비교)
		* 지능적 백업 전략: 한도 설정, 중요 버전만 보관
		* 자주 사용되지 않는 데이터는 아카이빙 저장소(cold storate)로 이동(aws s3 glacier)
	* 장애 처리
		* 로드밸런서: secondary 로드밸런서 필요, 로드밸런서끼리는 보통 heartbeat로 주기적 모니터링
		* 블록 저장소 서버: 다른 서버가 미완료/대기 작업을 이어받아야
		* 클라우드 저장소: 여러 지역 다중화, 다른 지역에서 획득
		* api 서버: 무상태 서버, 장애 서버를 회피/격리
		* 메타데이터 캐시: 다중화
		* 메타데이터 DB: 마스터-슬레이브
		* 알림 서비스: 드롭박스 알림 서비스 1대 당 롱 폴링 연결은 1백만개 이상, 롱 폴링 복구에 시간 소요
		* 오프라인 사용자 백업 큐: 다중화


## 16장 배움은 계속된다 
* 실세계 시스템들
	* 페이스북 타임라인: 비정규화의 힘
	* 페이스북 규모 확장성
	* 타임라인: 인생을 담기에 충분한 규모 확장성
	* 페이스북 채팅
	* 페이스북 사진 저장소
	* 페이스북 멀티피드
	* 페이스북 맴캐시 규모 확장성
	* 페이스북 소셜 그래프 분산 저장소
	* 아마존 아키텍처
	* 다이나모: 아마존 키-값 저장소
	* 넥플릭스 기술스택
	* 넥플릭스 추천 시스템
	* 구글 아키텍처
	* 구글 파일 시스템
	* 차이 기반 동기화(델타 동기화)
	* 유튜브 아키텍처
	* 유튜브의 규모 확장성
	* 빅테이블: 구조화 데이터를 위한 분산 저장소 시스템
	* 인스타그램 아키텍처
	* 트위터 시스템
	* 트위터 규모 확장하기
	* 스노플레이크
	* 타임라인과 규모 확장성 문제
	* 우버
	* 핀터레스트 규모확장성
	* 핀터레스트 아키텍처 업데이트
	* 링크드인 규모 확장성
	* 플리커 아키텍처
	* 드룹박스 규모 확장
	* 왓츠앱 아키텍처