## CHAPTER 1 벡터, 행렬, 배열
## 1.1 벡터 만들기
## 1.2 행렬 만들기
## 1.3 희소행렬 만들기
## 1.4 원소 선택하기
## 1.5 행렬 정보 확인하기
## 1.6 벡터화 연산 적용하기
## 1.7 최댓값, 최솟값 찾기
## 1.8 평균, 분산, 표준편차 계산하기
## 1.9 배열 크기 바꾸기
## 1.10 벡터나 행렬 전치하기
## 1.11 행렬 펼치기
## 1.12 행렬의 랭크 구하기
## 1.13 행렬식 계산하기
## 1.14 행렬의 대각원소 추출하기
## 1.15 행렬의 대각합 계산하기
## 1.16 고윳값과 고유벡터 찾기
## 1.17 점곱 계산하기
## 1.18 행렬 덧셈과 뺄셈
## 1.19 행렬 곱셈
## 1.20 역행렬
## 1.21 난수 생성하기


## CHAPTER 2 데이터 적재
## 2.1 샘플 데이터셋 적재하기
## 2.2 모의 데이터셋 만들기
## 2.3 CSV 파일 적재하기
## 2.4 엑셀 파일 적재하기
## 2.5 JSON 파일 적재하기
## 2.6 SQL 데이터베이스로부터 적재하기


## CHAPTER 3 데이터 랭글링
## 3.1 데이터프레임 만들기
## 3.2 데이터 설명하기
## 3.3 데이터프레임 탐색하기
## 3.4 조건에 따라 행 선택하기
## 3.5 값 치환하기
## 3.6 열 이름 바꾸기
## 3.7 최솟값, 최댓값, 합, 평균 계산 및 개수 세기
## 3.8 고유한 값 찾기
## 3.9 누락된 값 다루기
## 3.10 열 삭제하기
## 3.11 행 삭제하기
## 3.12 중복된 행 삭제하기
## 3.13 값에 따라 행을 그룹핑하기
## 3.14 시간에 따라 행을 그룹핑하기
## 3.15 열 원소 순회하기
## 3.16 모든 열 원소에 함수 적용하기
## 3.17 그룹에 함수 적용하기
## 3.18 데이터프레임 연결하기
## 3.19 데이터프레임 병합하기


## CHAPTER 4 수치형 데이터 다루기
## 4.1 특성 스케일 바꾸기
## 4.2 특성을 표준화하기
## 4.3 정규화하기
## 4.4 다항 특성과 교차항 특성 생성하기
## 4.5 특성 변환하기
## 4.6 이상치 감지하기
## 4.7 이상치 다루기
## 4.8 특성 이산화하기
## 4.9 군집으로 샘플을 그룹으로 묶기
## 4.10 누락된 값을 가진 샘플을 삭제하기
## 4.11 누락된 값 채우기


## CHAPTER 5 범주형 데이터 다루기
## 5.1 순서가 없는 범주형 특성 인코딩하기
## 5.2 순서가 있는 범주형 특성 인코딩하기
## 5.3 특성 딕셔너리를 인코딩하기
## 5.4 누락된 클래스 값 대체하기
## 5.5 불균형한 클래스 다루기


## CHAPTER 6 텍스트 다루기
## 6.1 텍스트 정제하기
## 6.2 HTML 파싱과 정제하기
## 6.3 구두점 삭제하기
## 6.4 텍스트 토큰화하기
## 6.5 불용어 삭제하기
## 6.6 어간 추출하기
## 6.7 품사 태깅하기
## 6.8 텍스트를 BoW로 인코딩하기
## 6.9 단어 중요도에 가중치 부여하기


## CHAPTER 7 날짜와 시간 다루기
## 7.1 문자열을 날짜로 변환하기
## 7.2 시간대 다루기
## 7.3 날짜와 시간 선택하기
## 7.4 날짜 데이터를 여러 특성으로 나누기
## 7.5 날짜 간의 차이를 계산하기
## 7.6 요일을 인코딩하기
## 7.7 시차 특성 만들기
## 7.8 이동 시간 윈도 사용하기
## 7.9 시계열 데이터에서 누락된 값 다루기


## CHAPTER 8 이미지 다루기
## 8.1 이미지 로드하기
## 8.2 이미지 저장하기
## 8.3 이미지 크기 변경하기
## 8.4 이미지 자르기
## 8.5 이미지 흐리게 하기
## 8.6 이미지 선명하게 하기
## 8.7 대비 높이기
## 8.8 색깔 구분하기
## 8.9 이미지 이진화하기
## 8.10 배경 제거하기
## 8.11 경계선 감지하기
## 8.12 모서리 감지하기
## 8.13 머신러닝 특성 만들기
## 8.14 평균 색을 특성으로 인코딩하기
## 8.15 컬러 히스토그램을 특성으로 인코딩하기


## CHAPTER 9 특성 추출을 사용한 차원 축소
## 9.1 주성분을 사용해 특성 줄이기
## 9.2 선형적으로 구분되지 않은 데이터의 차원 축소하기
## 9.3 클래스 분리를 최대화하여 특성 줄이기
## 9.4 행렬 분해를 사용하여 특성 줄이기
## 9.5 희소한 데이터의 특성 줄이기


## CHAPTER 10 특성 선택을 사용한 차원 축소
## 10.1 분산을 기준으로 수치 특성 선택하기
## 10.2 분산을 기준으로 이진 특성 선택하기
## 10.3 상관관계가 큰 특성 다루기
## 10.4 분류 작업에 관련 없는 특성 삭제하기
## 10.5 재귀적 특성 제거하기


## CHAPTER 11 모델 평가
## 11.1 교차검증 모델 만들기
## 11.2 기본 회귀 모델 만들기
## 11.3 기본 분류 모델 만들기
## 11.4 이진 분류기의 예측 평가하기
## 11.5 이진 분류기 임곗값 평가하기
## 11.6 다중클래스 분류기 예측 평가하기
## 11.7 분류기 성능 시각화하기
## 11.8 회귀 모델 평가하기
## 11.9 군집 모델 평가하기
## 11.10 사용자 정의 평가 지표 만들기
## 11.11 훈련 세트 크기에 따른 영향을 시각화하기
## 11.12 평가 지표 리포트 만들기
## 11.13 하이퍼파라미터 값의 영향을 시각화하기


## CHAPTER 12 모델 선택
## 12.1 완전 탐색을 사용해 최선의 모델 선택하기
## 12.2 랜덤 서치를 사용해 최선의 모델 선택하기
## 12.3 여러 학습 알고리즘에서 최선의 모델 선택하기
## 12.4 전처리와 함께 최선의 모델 선택하기
## 12.5 병렬화로 모델 선택 속도 높이기
## 12.6 알고리즘에 특화된 기법을 사용하여 모델 선택 수행 속도 높이기
## 12.7 모델 선택 후 성능 평가하기


## CHAPTER 13 선형회귀
## 13.1 직선 학습하기
## 13.2 교차 특성 다루기
## 13.3 비선형 관계 학습하기
## 13.4 규제로 분산 줄이기
## 13.5 라소 회귀로 특성 줄이기


## CHAPTER 14 트리와 랜덤 포레스트
## 14.1 결정 트리 분류기 훈련하기
## 14.2 결정 트리 회귀 훈련하기
## 14.3 결정 트리 모델 시각화하기
## 14.4 랜덤 포레스트 분류기 훈련하기
## 14.5 랜덤 포레스트 회귀 훈련하기
## 14.6 랜덤 포레스트에서 중요한 특성 구분하기
## 14.7 랜덤 포레스트에서 중요한 특성 선택하기
## 14.8 불균형한 클래스 다루기
## 14.9 트리 크기 제어하기
## 14.10 부스팅을 사용하여 성능 향상하기
## 14.11 OOB 데이터로 랜덤 포레스트 평가하기


## CHAPTER 15 k-최근접 이웃
## 15.1 샘플의 최근접 이웃 찾기
## 15.2 k-최근접 이웃 분류기 만들기
## 15.3 최선의 이웃 개수 결정하기
## 15.4 반지름 기반의 최근접 이웃 분류기 만들기


## CHAPTER 16 로지스틱 회귀
## 16.1 이진 분류기 훈련하기
## 16.2 다중 클래스 분류기 훈련하기
## 16.3 규제로 분산 줄이기
## 16.4 대용량 데이터에서 분류기 훈련하기
## 16.5 불균형한 클래스 다루기


## CHAPTER 17 서포트 벡터 머신
## 17.1 선형 분류기 훈련하기
## 17.2 커널을 사용해 선형적으로 구분되지 않는 클래스 다루기
## 17.3 예측 확률 계산하기
## 17.4 서포트 벡터 식별하기
## 17.5 불균형한 클래스 다루기


## CHAPTER 18 나이브 베이즈
## 18.1 연속적인 특성으로 분류기 훈련하기
## 18.2 이산적인 카운트 특성으로 분류기 훈련하기
## 18.3 이진 특성으로 나이브 베이즈 분류기 훈련하기
## 18.4 예측 확률 보정하기


## CHAPTER 19 군집
## 19.1 k-평균을 사용한 군집
## 19.2 k-평균 군집 속도 향상하기
## 19.3 평균이동을 사용한 군집
## 19.4 DBSCAN을 사용한 군집
## 19.5 계층적 병합을 사용한 군집


## CHAPTER 20 신경망
## 20.1 신경망을 위한 데이터 전처리하기
## 20.2 신경망 구성하기
## 20.3 이진 분류기 훈련하기
## 20.4 다중 분류기 훈련하기
## 20.5 회귀 모델 훈련하기
## 20.6 예측하기
## 20.7 훈련 기록 시각화하기
## 20.8 가중치 규제로 과대적합 줄이기
## 20.9 조기종료로 과대적합 줄이기
## 20.10 드롭아웃으로 과대적합 줄이기
## 20.11 모델 훈련 진행 과정을 저장하기
## 20.12 신경망을 k-폴드 교차검증하기
## 20.13 신경망 튜닝하기
## 20.14 신경망 시각화하기
## 20.15 이미지 분류하기
## 20.16 이미지 증식으로 성능 향상하기
## 20.17 텍스트 분류하기


## CHAPTER 21 훈련된 모델 저장과 복원
## 21.1 사이킷런 모델을 저장하고 복원하기
## 21.2 케라스 모델을 저장하고 복원하기 